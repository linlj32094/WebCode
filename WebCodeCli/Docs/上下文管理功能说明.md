# 智能上下文管理功能说明

## 📖 功能概述

智能上下文管理是 CodeAssistant 的核心增强功能，帮助您更好地管理与 Codex AI 的对话上下文，优化 Token 使用，提升交互效率。

## ✨ 核心功能

### 1. 自动提取代码片段

系统会自动从对话消息中提取代码块，并作为独立的上下文项进行管理。

**支持的代码块格式：**
```
```language
代码内容
```
```

**自动识别的语言：**
- C#, JavaScript, TypeScript, Python, Java, C++, Go, Rust
- HTML, CSS, JSON, XML, YAML, SQL
- Bash, PowerShell

**特性：**
- 自动检测代码语言
- 生成代码摘要（显示第一行和总行数）
- 独立的 Token 计算
- 可单独包含/排除

### 2. 智能压缩历史消息

当上下文达到设定阈值时，系统会自动触发压缩，节省 Token 使用。

**压缩策略：**

#### 保留最近消息 (KeepRecent)
- 保留最近的 N 条对话
- 移除旧的历史消息
- 适合：长时间对话，只关注最新内容

#### 保留高优先级 (KeepHighPriority)
- 按优先级排序，保留重要内容
- 移除低优先级项
- 适合：需要保留关键信息的场景

#### 智能摘要 (SmartSummary) ⭐ 推荐
- 保留高优先级项（优先级 ≥ 7）
- 保留最近的用户消息
- 对代码片段和文件内容生成摘要
- 移除低优先级且非最近的项
- 适合：大多数场景，平衡信息保留和 Token 节省

#### 移除重复 (RemoveDuplicates)
- 移除重复的代码片段和文件引用
- 基于内容哈希去重
- 适合：多次提交相同代码的场景

**自动压缩配置：**
```csharp
var config = new ContextManagerConfig
{
    MaxContextTokens = 100000,        // 最大上下文 Token 数
    AutoCompressThreshold = 0.8,      // 达到 80% 时自动压缩
    KeepRecentMessages = 5,           // 保留最近 5 条消息
    AutoExtractCodeSnippets = true,   // 自动提取代码片段
    AutoExtractFileReferences = true  // 自动提取文件引用
};
```

### 3. 上下文预览面板

点击工具栏的 **"上下文"** 按钮，打开上下文预览面板。

**面板功能：**

#### 统计信息
- Token 使用量和使用率
- 上下文项数量
- 剩余可用空间
- 按类型分组统计

#### 上下文项管理
- ✅ 勾选/取消勾选：包含/排除上下文项
- 🔼🔽 调整优先级：影响压缩时的保留决策
- 🔍 搜索：按关键词搜索上下文项
- 🏷️ 筛选：按类型筛选（用户消息、助手消息、代码片段等）

#### 上下文项类型
| 类型 | 说明 | 徽章颜色 |
|------|------|----------|
| 用户消息 | 您发送的消息 | 蓝色 |
| 助手消息 | AI 的回复 | 绿色 |
| 代码片段 | 提取的代码块 | 紫色 |
| 文件引用 | 提到的文件路径 | 橙色 |
| 工作区文件 | 工作区中的文件 | 靛蓝色 |
| 错误消息 | 错误信息 | 红色 |

#### 操作按钮
- **刷新**：重新加载上下文
- **导出**：导出上下文为 JSON（用于调试或分享）
- **压缩**：手动触发压缩

### 4. 手动选择/排除消息

**操作方式：**

1. 打开上下文预览面板
2. 找到要操作的上下文项
3. 点击复选框或卡片，切换包含/排除状态
4. 被排除的项会显示为半透明，不会发送给 AI

**优先级调整：**
- 点击 🔼 提高优先级（0-10）
- 点击 🔽 降低优先级
- 高优先级项（≥7）在压缩时会被优先保留
- 高优先级项会显示 ⭐ 图标

## 🎯 使用场景

### 场景 1：长时间对话优化

**问题：** 对话太长，Token 消耗过大

**解决方案：**
1. 打开上下文面板，查看 Token 使用情况
2. 排除不重要的历史消息
3. 或使用 "保留最近消息" 压缩策略

### 场景 2：保留关键代码片段

**问题：** 需要 AI 记住之前讨论的代码

**解决方案：**
1. 系统会自动提取代码片段
2. 找到重要的代码片段，提高其优先级（设为 8-10）
3. 压缩时会优先保留这些代码

### 场景 3：添加工作区文件作为上下文

**问题：** 需要 AI 了解工作区中的某个文件

**解决方案：**
```csharp
// 通过代码添加
await ContextManagerService.AddWorkspaceFileToContextAsync(sessionId, "src/utils.ts");

// 或批量添加
await ContextManagerService.AddWorkspaceFilesToContextAsync(sessionId, new List<string>
{
    "src/utils.ts",
    "src/types.ts",
    "README.md"
});
```

### 场景 4：调试上下文问题

**问题：** AI 的回复不符合预期，怀疑上下文有问题

**解决方案：**
1. 打开上下文面板
2. 检查哪些项被包含
3. 导出上下文查看详细内容
4. 调整包含/排除状态或优先级

## 📊 Token 估算

系统使用简单的启发式算法估算 Token 数量：

- **英文文本**：约 4 字符 = 1 Token
- **中文文本**：约 1.5 字符 = 1 Token
- **代码**：约 3.5 字符 = 1 Token（代码通常更密集）

**注意：** 这只是估算值，实际 Token 数量由 OpenAI 的 Tokenizer 决定。

## 🔧 高级用法

### 编程式上下文管理

```csharp
// 1. 构建上下文
var contextItems = await ContextManagerService.BuildContextFromMessagesAsync(sessionId, messages);

// 2. 添加自定义上下文项
var customItem = new ContextItem
{
    Type = ContextItemType.CodeSnippet,
    Content = "function hello() { console.log('Hello'); }",
    Language = "javascript",
    Priority = 8,
    Tags = new List<string> { "important", "example" }
};
ContextManagerService.AddContextItem(sessionId, customItem);

// 3. 搜索上下文
var results = ContextManagerService.SearchContextItems(sessionId, "hello");

// 4. 按类型筛选
var codeSnippets = ContextManagerService.FilterContextItemsByType(sessionId, ContextItemType.CodeSnippet);

// 5. 生成摘要
var summary = await ContextManagerService.GenerateContextSummaryAsync(sessionId);

// 6. 手动压缩
var result = await ContextManagerService.CompressContextAsync(sessionId, CompressionStrategy.SmartSummary);
Console.WriteLine($"节省了 {result.TokensSaved} tokens ({result.CompressionRatio:F1}%)");

// 7. 导出/导入
var json = await ContextManagerService.ExportContextAsync(sessionId);
await ContextManagerService.ImportContextAsync(newSessionId, json);
```

### 自定义压缩配置

```csharp
// 在 appsettings.json 中配置
{
  "ContextManager": {
    "MaxContextTokens": 150000,
    "AutoCompressThreshold": 0.75,
    "KeepRecentMessages": 10,
    "AutoExtractCodeSnippets": true,
    "AutoExtractFileReferences": true,
    "MinCodeSnippetLines": 5,
    "MaxCodeSnippetLines": 200
  }
}
```

## 💡 最佳实践

### 1. 定期检查上下文

每隔一段时间打开上下文面板，检查：
- Token 使用率是否过高
- 是否有不需要的项被包含
- 重要信息是否设置了高优先级

### 2. 合理设置优先级

**优先级建议：**
- 10：关键代码、核心需求
- 8-9：重要的讨论、主要功能
- 5-7：一般对话、辅助信息
- 3-4：次要内容、历史记录
- 0-2：可随时丢弃的内容

### 3. 善用压缩策略

- **初期对话**：使用 "智能摘要"，平衡保留和节省
- **长期对话**：使用 "保留最近消息"，聚焦当前话题
- **重要项目**：使用 "保留高优先级"，确保关键信息不丢失
- **代码重构**：使用 "移除重复"，避免相同代码占用空间

### 4. 导出重要上下文

对于重要的对话，定期导出上下文：
- 作为项目文档的一部分
- 分享给团队成员
- 作为备份，防止意外丢失

## 🐛 故障排除

### 问题 1：Token 使用率一直很高

**解决方案：**
1. 手动触发压缩
2. 排除不重要的历史消息
3. 降低 `AutoCompressThreshold` 配置

### 问题 2：AI 忘记了之前的代码

**解决方案：**
1. 检查代码片段是否被排除
2. 提高相关代码片段的优先级
3. 手动添加工作区文件到上下文

### 问题 3：压缩后 AI 回复质量下降

**解决方案：**
1. 使用 "智能摘要" 而不是 "保留最近消息"
2. 提高重要项的优先级
3. 增加 `KeepRecentMessages` 配置值

### 问题 4：上下文面板加载缓慢

**解决方案：**
1. 减少上下文项数量（定期清理）
2. 使用搜索和筛选功能，而不是查看全部
3. 考虑分割长对话为多个会话

## 📈 性能优化

### Token 使用优化

- 自动压缩可节省 20-40% 的 Token
- 移除重复可节省 10-20% 的 Token
- 智能摘要可节省 30-50% 的 Token

### 响应速度优化

- 上下文构建使用异步处理，不阻塞 UI
- 防抖机制避免频繁更新
- 增量更新，只处理变化的部分

## 🔮 未来计划

- [ ] 基于 AI 的智能摘要生成
- [ ] 上下文可视化（关系图、时间线）
- [ ] 上下文模板（快速应用预设配置）
- [ ] 跨会话上下文共享
- [ ] 更精确的 Token 计算（集成 OpenAI Tokenizer）
- [ ] 上下文分析报告（Token 使用趋势、优化建议）

## 📚 相关资源

- [Codex CLI 文档](https://github.com/openai/codex)
- [OpenAI Token 计算](https://platform.openai.com/tokenizer)
- [上下文管理最佳实践](./上下文管理最佳实践.md)

---

**版本：** 1.0.0  
**最后更新：** 2025-01-01  
**作者：** WebCodeCli Team

